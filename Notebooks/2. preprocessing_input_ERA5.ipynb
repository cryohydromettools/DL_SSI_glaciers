{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import dateutil\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "from utilities.era5_down import era5_down\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_parser = lambda x: dateutil.parser.parse(x, ignoretz=True)\n",
    "# Improved function to sum dataframe columns which contain nan's\n",
    "def nansumwrapper(a, **kwargs):\n",
    "    if np.isnan(a).all():\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.nansum(a, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_file = '../data/loc_stakes_SMB.csv'\n",
    "dfmb = pd.read_csv(cs_file,\n",
    "   delimiter='\\t', index_col=['Date/Time'],\n",
    "    parse_dates=['Date/Time'], na_values='NAN',date_parser=date_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dfmb.drop_duplicates(subset=['Event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m = 't2m'\n",
    "rh2 = 'rh'\n",
    "ff  = 'u2'\n",
    "Prec = 'tp'\n",
    "Snowfall = 'sf'\n",
    "SWD = 'SWin'\n",
    "LWD = 'LWin'\n",
    "Pres = 'press'\n",
    "fcc  = 'tcc'\n",
    "msl  = 'msl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(glob.glob('../data/ERA_59_20_day/*.nc'))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stake_inp = []\n",
    "for i in labels['Event']:#[0:2]    \n",
    "    stake = dfmb.loc[lambda df: df['Event'] == i, :]\n",
    "    df_day = era5_down(files, stake['Longitude'][0], \n",
    "               stake['Latitude'][0], stake['Elevation [m]'][0])\n",
    "    df_day['t2m_an'] = (df_day[t2m] - df_day[t2m].mean())/df_day[t2m].std()\n",
    "    str_date = stake.index.values[0]\n",
    "    end_date = stake.index.values[1]\n",
    "    subset = df_day.loc[str_date:end_date].copy()\n",
    "    subset['PDD'] = subset[t2m].where(subset[t2m] > 0, 0).where(subset[t2m] <= 0, 1)\n",
    "    subset['stake'] = stake['Event'][0]\n",
    "    subset_f = subset.groupby(['stake']).agg({t2m:np.mean, rh2:np.mean, ff:np.mean, \n",
    "                                     SWD:np.mean, LWD:np.mean, Prec:nansumwrapper,\n",
    "                                     Snowfall:nansumwrapper, msl:np.mean,\n",
    "                                     Pres:np.mean, fcc:np.mean, 't2m_an':np.mean,\n",
    "                                     'PDD':nansumwrapper})\n",
    "    subset_f.index = ([str_date])\n",
    "    subset_f0 = []\n",
    "    for i in range(len(stake)-1):\n",
    "        str_date = stake.index.values[i]\n",
    "        end_date = stake.index.values[i+1]\n",
    "        subset = df_day.loc[str_date:end_date].copy()\n",
    "        subset['PDD'] = subset[t2m].where(subset[t2m] > 0, 0).where(subset[t2m] <= 0, 1)\n",
    "        subset['stake'] = stake['Event'][0]\n",
    "        subset0 = subset.groupby(['stake']).agg({t2m:np.mean, rh2:np.mean, ff:np.mean, \n",
    "                                         SWD:np.mean, LWD:np.mean, Prec:nansumwrapper,\n",
    "                                         Snowfall:nansumwrapper, msl:np.mean,\n",
    "                                         Pres:np.mean, fcc:np.mean, 't2m_an':np.mean,\n",
    "                                         'PDD':nansumwrapper})\n",
    "        subset0.index = ([end_date])\n",
    "        subset_f0.append(subset0)\n",
    "    subset_f0 = pd.concat(subset_f0)\n",
    "    subset_f[[Prec, 'PDD']] = 0.0\n",
    "    subset_ff = pd.concat([subset_f, subset_f0])\n",
    "    subset_fff = pd.concat([stake, subset_ff], axis=1)\n",
    "    stake_inp.append(subset_fff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stake_inp = pd.concat(stake_inp)\n",
    "stake_inp.index.name = 'Date/Time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stake_inp.to_csv('../data/SMB_input_2011_2016_ERA5.csv', index=True, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_SMB",
   "language": "python",
   "name": "dl_smb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
