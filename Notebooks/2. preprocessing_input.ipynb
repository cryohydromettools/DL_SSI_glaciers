{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dateutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_parser = lambda x: dateutil.parser.parse(x, ignoretz=True)\n",
    "# Improved function to sum dataframe columns which contain nan's\n",
    "def nansumwrapper(a, **kwargs):\n",
    "    if np.isnan(a).all():\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.nansum(a, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m = 'TTT [Â°C]'\n",
    "rh2 = 'RH [%]'\n",
    "ff  = 'ff [m/s]'\n",
    "Prec = 'Precip [mm/h]'\n",
    "SWD = 'SWD [W/m**2]'\n",
    "LWD = 'LWD [W/m**2]'\n",
    "Pres = 'PPPP [hPa]'\n",
    "fcc  = 'Clouds [octa]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_file = '../data/KGI_AWS_met_obs_V2.tab'\n",
    "df = pd.read_csv(cs_file,\n",
    "                 delimiter='\\t', index_col=['Date/Time'],\n",
    "                 parse_dates=['Date/Time'], na_values='NAN',date_parser=date_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = df.resample('1d').agg({t2m:np.mean, rh2:np.mean, ff:np.mean, \n",
    "                                SWD:np.mean, LWD:np.mean, Prec:nansumwrapper,\n",
    "                                Pres:np.mean, fcc:np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day['t2m_an'] = (df_day[t2m] - df_day[t2m].mean())/df_day[t2m].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_file = '../data/loc_stakes_SMB_2011_2015.csv'\n",
    "dfmb = pd.read_csv(cs_file,\n",
    "   delimiter='\\t', index_col=['Date/Time'],\n",
    "    parse_dates=['Date/Time'], na_values='NAN',date_parser=date_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dfmb.drop_duplicates(subset=['Event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stake_inp = []\n",
    "for i in labels['Event']:#[0:4]\n",
    "    \n",
    "    stake = dfmb.loc[lambda df: df['Event'] == i, :]\n",
    "    str_date = stake.index.values[0]\n",
    "    end_date = stake.index.values[1]\n",
    "    subset = df_day.loc[str_date:end_date].copy()\n",
    "    hgt_era = stake['Elevation [m]'][0]\n",
    "    hgt_aws = 194.5\n",
    "    subset[t2m] = subset[t2m].values + (hgt_era - hgt_aws) * -0.006\n",
    "    subset['PDD'] = subset[t2m].where(subset[t2m] > 0, 0).where(subset[t2m] <= 0, 1)\n",
    "    subset['stake'] = stake['Event'][0]\n",
    "    subset_f = subset.groupby(['stake']).agg({t2m:np.mean, rh2:np.mean, ff:np.mean, \n",
    "                                     SWD:np.mean, LWD:np.mean, Prec:nansumwrapper,\n",
    "                                     Pres:np.mean, fcc:np.mean, 't2m_an':np.mean,\n",
    "                                     'PDD':nansumwrapper})\n",
    "    subset_f.index = ([str_date])\n",
    "    subset_f0 = []\n",
    "    for i in range(len(stake)-1):\n",
    "        str_date = stake.index.values[i]\n",
    "        end_date = stake.index.values[i+1]\n",
    "        subset = df_day.loc[str_date:end_date].copy()\n",
    "        hgt_era = stake['Elevation [m]'][0]\n",
    "        hgt_aws = 194.5\n",
    "        subset[t2m] = subset[t2m].values + (hgt_era - hgt_aws) * -0.006\n",
    "        subset['PDD'] = subset[t2m].where(subset[t2m] > 0, 0).where(subset[t2m] <= 0, 1)\n",
    "        subset['stake'] = stake['Event'][0]\n",
    "        subset0 = subset.groupby(['stake']).agg({t2m:np.mean, rh2:np.mean, ff:np.mean, \n",
    "                                         SWD:np.mean, LWD:np.mean, Prec:nansumwrapper,\n",
    "                                         Pres:np.mean, fcc:np.mean, 't2m_an':np.mean,\n",
    "                                         'PDD':nansumwrapper})\n",
    "        subset0.index = ([end_date])\n",
    "        subset_f0.append(subset0)\n",
    "    subset_f0 = pd.concat(subset_f0)\n",
    "    subset_f[[Prec, 'PDD']] = 0.0\n",
    "    subset_ff = pd.concat([subset_f, subset_f0])\n",
    "    subset_fff = pd.concat([stake, subset_ff], axis=1)\n",
    "    stake_inp.append(subset_fff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stake_inp = pd.concat(stake_inp)\n",
    "stake_inp.index.name = 'Date/Time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stake_inp.to_csv('../data/SMB_input_2011_2015.csv', index=True, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
